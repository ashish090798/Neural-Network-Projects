{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image_Classification_Intro_to_NN_3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bGyHWbOM70HN"},"source":["## Image Classification\n","\n","\n","Image classification is one of the important use cases in our daily life. Automotive, e-commerce, retail, manufacturing industries, security, surveillance, healthcare, farming etc., can have a wide application of image classification.\n","\n","**Objective:** In this notebook, we will build a neural network to classifiy the image based on the object present in the image.\n"]},{"cell_type":"markdown","metadata":{"id":"8LSdjqV35-j_"},"source":["\n","## Advanced techniques for training neural networks\n","\n","Weight Initialization\n","\n","Nonlinearity (different Activation functions)\n","\n","Optimizers(different optimizers)\n","\n","Batch Normalization\n","\n","Dropout"]},{"cell_type":"markdown","metadata":{"id":"XfL8u4jx82pG"},"source":["### About Dataset\n","\n","\n","Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255. The training and test data sets have 785 columns. The first column consists of the class labels (see above), and represents the article of clothing. The rest of the columns contain the pixel-values of the associated image.\n","\n","#### Labels\n","\n","Each training and test example is assigned to one of the following labels:\n","\n","0 T-shirt/top\n","\n","1 Trouser\n","\n","2 Pullover\n","\n","3 Dress\n","\n","4 Coat\n","\n","5 Sandal\n","\n","6 Shirt\n","\n","7 Sneaker\n","\n","8 Bag\n","\n","9 Ankle boot "]},{"cell_type":"markdown","metadata":{"id":"-XGznu8t6HBc"},"source":["### Load dataset\n","\n","Fashion-MNIST dataset\n"]},{"cell_type":"code","metadata":{"id":"yeUlXwljJF8x","executionInfo":{"status":"ok","timestamp":1653502219898,"user_tz":-330,"elapsed":10,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["%tensorflow_version 2.x"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"3m64izx05_VU","executionInfo":{"status":"ok","timestamp":1653502222707,"user_tz":-330,"elapsed":2817,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import fashion_mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.utils import to_categorical"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAkQmLqP6I2W","outputId":"09e115c5-4a7b-46d9-c45d-ce9028f7ac50","executionInfo":{"status":"ok","timestamp":1653502223310,"user_tz":-330,"elapsed":634,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"Mr5bH4OY6Ndk","outputId":"104c2bf6-111c-4760-d462-3a34f0fbac77","executionInfo":{"status":"ok","timestamp":1653502223313,"user_tz":-330,"elapsed":45,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["plt.imshow(X_train[0])    # show first number in the dataset\n","plt.show()\n","print('Label: ', y_train[0])\n"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["Label:  9\n"]}]},{"cell_type":"code","metadata":{"id":"bcTZqYFj6PcB","outputId":"99d493b8-9067-49a3-cd0b-97b08377241f","executionInfo":{"status":"ok","timestamp":1653502223315,"user_tz":-330,"elapsed":39,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["plt.imshow(X_test[0])    # show first number in the dataset\n","plt.show()\n","print('Label: ', y_test[0])"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["Label:  9\n"]}]},{"cell_type":"markdown","metadata":{"id":"JZxmqqAa9Cz7"},"source":["### Data Pre-processing"]},{"cell_type":"code","metadata":{"id":"5TCY3Jnm6RHr","executionInfo":{"status":"ok","timestamp":1653502223316,"user_tz":-330,"elapsed":37,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["# reshaping X data: (n, 28, 28) => (n, 784)\n","X_train = X_train.reshape((X_train.shape[0], -1))\n","X_test = X_test.reshape((X_test.shape[0], -1))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"oG06URdH6Vvv","executionInfo":{"status":"ok","timestamp":1653502223317,"user_tz":-330,"elapsed":37,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["# converting y data into categorical (one-hot encoding)\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"71HK9T0P6Y2G","outputId":"dc62c855-0083-47fc-b9e9-ef9c0d95e550","executionInfo":{"status":"ok","timestamp":1653502223318,"user_tz":-330,"elapsed":37,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 784) (10000, 784) (60000, 10) (10000, 10)\n"]}]},{"cell_type":"markdown","metadata":{"id":"yb0Kx_ME6plD"},"source":["### Basic NN model\n","\n","Naive MLP model without any alterations"]},{"cell_type":"code","metadata":{"id":"weHT53gF6aFY","executionInfo":{"status":"ok","timestamp":1653502223320,"user_tz":-330,"elapsed":32,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Activation, Dense\n","from tensorflow.keras import optimizers"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"izZlXqJu6sdo","executionInfo":{"status":"ok","timestamp":1653502226707,"user_tz":-330,"elapsed":3417,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["model = Sequential()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"3dCi-i296tuq","executionInfo":{"status":"ok","timestamp":1653502228346,"user_tz":-330,"elapsed":1685,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["  model.add(Dense(50, input_shape = (784, )))\n","  model.add(Activation('sigmoid'))\n","  model.add(Dense(50))\n","  model.add(Activation('sigmoid'))\n","  model.add(Dense(50))\n","  model.add(Activation('sigmoid'))\n","  model.add(Dense(50))\n","  model.add(Activation('sigmoid'))\n","  model.add(Dense(10))\n","  model.add(Activation('softmax'))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"PJ5FUE916x2b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653502228347,"user_tz":-330,"elapsed":18,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"outputId":"3a2126c0-89ba-4b0c-b1c0-a337ffaee0ef"},"source":["sgd = optimizers.SGD(lr = 0.01)\n","model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","metadata":{"id":"Zl34l0jR6zH-","outputId":"61e4e5f1-614f-40d6-e81a-fa807b3b3883","executionInfo":{"status":"ok","timestamp":1653502369923,"user_tz":-330,"elapsed":141590,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["history = model.fit(X_train, y_train, batch_size = 200, epochs = 100, verbose = 1)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","300/300 [==============================] - 5s 5ms/step - loss: 2.3093 - accuracy: 0.1066\n","Epoch 2/100\n","300/300 [==============================] - 1s 5ms/step - loss: 2.2982 - accuracy: 0.1623\n","Epoch 3/100\n","300/300 [==============================] - 1s 5ms/step - loss: 2.2959 - accuracy: 0.1679\n","Epoch 4/100\n","300/300 [==============================] - 1s 2ms/step - loss: 2.2937 - accuracy: 0.2140\n","Epoch 5/100\n","300/300 [==============================] - 1s 2ms/step - loss: 2.2907 - accuracy: 0.2069\n","Epoch 6/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2873 - accuracy: 0.2657\n","Epoch 7/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2828 - accuracy: 0.2808\n","Epoch 8/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2777 - accuracy: 0.3254\n","Epoch 9/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2721 - accuracy: 0.3639\n","Epoch 10/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2648 - accuracy: 0.3609\n","Epoch 11/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2551 - accuracy: 0.3307\n","Epoch 12/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2418 - accuracy: 0.3510\n","Epoch 13/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2238 - accuracy: 0.3408\n","Epoch 14/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1985 - accuracy: 0.2976\n","Epoch 15/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1625 - accuracy: 0.2966\n","Epoch 16/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1111 - accuracy: 0.2858\n","Epoch 17/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.0423 - accuracy: 0.2670\n","Epoch 18/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.9596 - accuracy: 0.2882\n","Epoch 19/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.8755 - accuracy: 0.2788\n","Epoch 20/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.8021 - accuracy: 0.3139\n","Epoch 21/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.7432 - accuracy: 0.3213\n","Epoch 22/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.6971 - accuracy: 0.3639\n","Epoch 23/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.6585 - accuracy: 0.3897\n","Epoch 24/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.6225 - accuracy: 0.3880\n","Epoch 25/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.5884 - accuracy: 0.3890\n","Epoch 26/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.5554 - accuracy: 0.4052\n","Epoch 27/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.5237 - accuracy: 0.3931\n","Epoch 28/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.4934 - accuracy: 0.4002\n","Epoch 29/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.4653 - accuracy: 0.3975\n","Epoch 30/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.4399 - accuracy: 0.4030\n","Epoch 31/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.4163 - accuracy: 0.4100\n","Epoch 32/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.3943 - accuracy: 0.4102\n","Epoch 33/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.3745 - accuracy: 0.4042\n","Epoch 34/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.3570 - accuracy: 0.4165\n","Epoch 35/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.3394 - accuracy: 0.4153\n","Epoch 36/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.3232 - accuracy: 0.4223\n","Epoch 37/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.3085 - accuracy: 0.4352\n","Epoch 38/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.2953 - accuracy: 0.4286\n","Epoch 39/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.2823 - accuracy: 0.4332\n","Epoch 40/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.2695 - accuracy: 0.4504\n","Epoch 41/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.2568 - accuracy: 0.4539\n","Epoch 42/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.2446 - accuracy: 0.4576\n","Epoch 43/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.2318 - accuracy: 0.4661\n","Epoch 44/100\n","300/300 [==============================] - 1s 2ms/step - loss: 1.2213 - accuracy: 0.4767\n","Epoch 45/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.2094 - accuracy: 0.4841\n","Epoch 46/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1983 - accuracy: 0.4937\n","Epoch 47/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1859 - accuracy: 0.4993\n","Epoch 48/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1765 - accuracy: 0.5070\n","Epoch 49/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1665 - accuracy: 0.5077\n","Epoch 50/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1548 - accuracy: 0.5228\n","Epoch 51/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1449 - accuracy: 0.5303\n","Epoch 52/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1352 - accuracy: 0.5239\n","Epoch 53/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1255 - accuracy: 0.5332\n","Epoch 54/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1136 - accuracy: 0.5490\n","Epoch 55/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.1034 - accuracy: 0.5524\n","Epoch 56/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.0956 - accuracy: 0.5610\n","Epoch 57/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.0846 - accuracy: 0.5724\n","Epoch 58/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.0738 - accuracy: 0.5718\n","Epoch 59/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.0612 - accuracy: 0.5825\n","Epoch 60/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.0458 - accuracy: 0.5994\n","Epoch 61/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.0369 - accuracy: 0.6008\n","Epoch 62/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.0241 - accuracy: 0.6134\n","Epoch 63/100\n","300/300 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.6247\n","Epoch 64/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9937 - accuracy: 0.6296\n","Epoch 65/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9819 - accuracy: 0.6461\n","Epoch 66/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9670 - accuracy: 0.6439\n","Epoch 67/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9574 - accuracy: 0.6547\n","Epoch 68/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9464 - accuracy: 0.6547\n","Epoch 69/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9319 - accuracy: 0.6675\n","Epoch 70/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9241 - accuracy: 0.6746\n","Epoch 71/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9201 - accuracy: 0.6809\n","Epoch 72/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9167 - accuracy: 0.6788\n","Epoch 73/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9092 - accuracy: 0.6855\n","Epoch 74/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.9054 - accuracy: 0.6909\n","Epoch 75/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8963 - accuracy: 0.6895\n","Epoch 76/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8775 - accuracy: 0.7019\n","Epoch 77/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8707 - accuracy: 0.7102\n","Epoch 78/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8658 - accuracy: 0.7135\n","Epoch 79/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8577 - accuracy: 0.7175\n","Epoch 80/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8465 - accuracy: 0.7246\n","Epoch 81/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8368 - accuracy: 0.7345\n","Epoch 82/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8227 - accuracy: 0.7401\n","Epoch 83/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8127 - accuracy: 0.7449\n","Epoch 84/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.8032 - accuracy: 0.7494\n","Epoch 85/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7956 - accuracy: 0.7419\n","Epoch 86/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7853 - accuracy: 0.7517\n","Epoch 87/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7767 - accuracy: 0.7495\n","Epoch 88/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7678 - accuracy: 0.7538\n","Epoch 89/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7613 - accuracy: 0.7522\n","Epoch 90/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7534 - accuracy: 0.7543\n","Epoch 91/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7520 - accuracy: 0.7560\n","Epoch 92/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7464 - accuracy: 0.7534\n","Epoch 93/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7386 - accuracy: 0.7540\n","Epoch 94/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7275 - accuracy: 0.7584\n","Epoch 95/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7200 - accuracy: 0.7603\n","Epoch 96/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7108 - accuracy: 0.7621\n","Epoch 97/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7040 - accuracy: 0.7636\n","Epoch 98/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.7051 - accuracy: 0.7626\n","Epoch 99/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.6985 - accuracy: 0.7662\n","Epoch 100/100\n","300/300 [==============================] - 1s 3ms/step - loss: 0.6945 - accuracy: 0.7632\n"]}]},{"cell_type":"code","metadata":{"id":"Rhl0xqgR62ei","outputId":"87ad11d1-f83a-41f2-f4d3-30f40ff8458f","executionInfo":{"status":"ok","timestamp":1653502370573,"user_tz":-330,"elapsed":663,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["results = model.evaluate(X_test, y_test)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 2ms/step - loss: 0.7254 - accuracy: 0.7638\n"]}]},{"cell_type":"code","metadata":{"id":"6PSheNKy66Iu","outputId":"3c86163d-fb4a-4f85-ebcd-a9ddd1d980e2","executionInfo":{"status":"ok","timestamp":1653502371063,"user_tz":-330,"elapsed":504,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Test accuracy: ', results[1])"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy:  0.7638000249862671\n"]}]},{"cell_type":"markdown","metadata":{"id":"3V7kN5-f7IHv"},"source":["### 1. Weight Initialization\n","\n","Changing weight initialization scheme can significantly improve training of the model by preventing vanishing gradient problem up to some degree\n","\n","Ref: https://keras.io/initializers/"]},{"cell_type":"code","metadata":{"id":"7il0ZpZZ67GP","executionInfo":{"status":"ok","timestamp":1653502371064,"user_tz":-330,"elapsed":11,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["# from now on, create a function to generate (return) models\n","def mlp_model():\n","    model = Sequential()\n","    \n","    model.add(Dense(50, input_shape = (784, ), kernel_initializer='he_normal'))     # use he_normal initializer\n","    model.add(Activation('sigmoid'))    \n","    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n","    model.add(Activation('sigmoid'))    \n","    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n","    model.add(Activation('sigmoid'))    \n","    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n","    model.add(Activation('sigmoid'))    \n","    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n","    model.add(Activation('softmax'))\n","    \n","    sgd = optimizers.SGD(lr = 0.001)\n","    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    \n","    return model"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"9iOQeOzR7Q2O","outputId":"f2a7f1ff-71a7-4fd0-f325-f3fe05a2a8c5","executionInfo":{"status":"ok","timestamp":1653502449980,"user_tz":-330,"elapsed":78926,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["model = mlp_model()\n","history = model.fit(X_train, y_train, batch_size=200, epochs = 100, verbose = 1)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["300/300 [==============================] - 1s 3ms/step - loss: 2.3867 - accuracy: 0.1096\n","Epoch 2/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.3386 - accuracy: 0.1172\n","Epoch 3/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.3156 - accuracy: 0.1285\n","Epoch 4/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.3043 - accuracy: 0.1221\n","Epoch 5/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2985 - accuracy: 0.1449\n","Epoch 6/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2952 - accuracy: 0.1746\n","Epoch 7/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2931 - accuracy: 0.2010\n","Epoch 8/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2916 - accuracy: 0.2520\n","Epoch 9/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2903 - accuracy: 0.2573\n","Epoch 10/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2892 - accuracy: 0.2941\n","Epoch 11/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2882 - accuracy: 0.3327\n","Epoch 12/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2872 - accuracy: 0.3408\n","Epoch 13/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2862 - accuracy: 0.3658\n","Epoch 14/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2852 - accuracy: 0.3629\n","Epoch 15/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2842 - accuracy: 0.3790\n","Epoch 16/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2832 - accuracy: 0.3784\n","Epoch 17/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2822 - accuracy: 0.3881\n","Epoch 18/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2813 - accuracy: 0.3948\n","Epoch 19/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2803 - accuracy: 0.4008\n","Epoch 20/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2794 - accuracy: 0.4039\n","Epoch 21/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2784 - accuracy: 0.4087\n","Epoch 22/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2775 - accuracy: 0.4182\n","Epoch 23/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2766 - accuracy: 0.4190\n","Epoch 24/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2756 - accuracy: 0.4259\n","Epoch 25/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2747 - accuracy: 0.4292\n","Epoch 26/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2738 - accuracy: 0.4327\n","Epoch 27/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2729 - accuracy: 0.4301\n","Epoch 28/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2720 - accuracy: 0.4301\n","Epoch 29/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2710 - accuracy: 0.4294\n","Epoch 30/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2701 - accuracy: 0.4329\n","Epoch 31/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2691 - accuracy: 0.4344\n","Epoch 32/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2681 - accuracy: 0.4408\n","Epoch 33/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2671 - accuracy: 0.4349\n","Epoch 34/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2662 - accuracy: 0.4432\n","Epoch 35/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2651 - accuracy: 0.4553\n","Epoch 36/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2641 - accuracy: 0.4481\n","Epoch 37/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2631 - accuracy: 0.4592\n","Epoch 38/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2620 - accuracy: 0.4576\n","Epoch 39/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2610 - accuracy: 0.4572\n","Epoch 40/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2599 - accuracy: 0.4566\n","Epoch 41/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2587 - accuracy: 0.4629\n","Epoch 42/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2576 - accuracy: 0.4602\n","Epoch 43/100\n","300/300 [==============================] - 1s 2ms/step - loss: 2.2564 - accuracy: 0.4634\n","Epoch 44/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2551 - accuracy: 0.4671\n","Epoch 45/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2537 - accuracy: 0.4647\n","Epoch 46/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2523 - accuracy: 0.4637\n","Epoch 47/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2507 - accuracy: 0.4683\n","Epoch 48/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2490 - accuracy: 0.4663\n","Epoch 49/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2474 - accuracy: 0.4667\n","Epoch 50/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2458 - accuracy: 0.4637\n","Epoch 51/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2442 - accuracy: 0.4659\n","Epoch 52/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2426 - accuracy: 0.4652\n","Epoch 53/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2410 - accuracy: 0.4705\n","Epoch 54/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2394 - accuracy: 0.4664\n","Epoch 55/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2377 - accuracy: 0.4662\n","Epoch 56/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2359 - accuracy: 0.4651\n","Epoch 57/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2341 - accuracy: 0.4645\n","Epoch 58/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2323 - accuracy: 0.4649\n","Epoch 59/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2303 - accuracy: 0.4656\n","Epoch 60/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2284 - accuracy: 0.4610\n","Epoch 61/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2263 - accuracy: 0.4625\n","Epoch 62/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2242 - accuracy: 0.4613\n","Epoch 63/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2220 - accuracy: 0.4606\n","Epoch 64/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2198 - accuracy: 0.4577\n","Epoch 65/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2174 - accuracy: 0.4557\n","Epoch 66/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2150 - accuracy: 0.4538\n","Epoch 67/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2126 - accuracy: 0.4569\n","Epoch 68/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2100 - accuracy: 0.4548\n","Epoch 69/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2074 - accuracy: 0.4537\n","Epoch 70/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2047 - accuracy: 0.4546\n","Epoch 71/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.2019 - accuracy: 0.4520\n","Epoch 72/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1991 - accuracy: 0.4519\n","Epoch 73/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1962 - accuracy: 0.4474\n","Epoch 74/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1932 - accuracy: 0.4512\n","Epoch 75/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1901 - accuracy: 0.4476\n","Epoch 76/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1869 - accuracy: 0.4488\n","Epoch 77/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1835 - accuracy: 0.4457\n","Epoch 78/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1801 - accuracy: 0.4446\n","Epoch 79/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1766 - accuracy: 0.4452\n","Epoch 80/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1731 - accuracy: 0.4408\n","Epoch 81/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1693 - accuracy: 0.4419\n","Epoch 82/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1655 - accuracy: 0.4452\n","Epoch 83/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1616 - accuracy: 0.4404\n","Epoch 84/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1575 - accuracy: 0.4375\n","Epoch 85/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1533 - accuracy: 0.4408\n","Epoch 86/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1489 - accuracy: 0.4365\n","Epoch 87/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1444 - accuracy: 0.4331\n","Epoch 88/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1398 - accuracy: 0.4339\n","Epoch 89/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1350 - accuracy: 0.4294\n","Epoch 90/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1300 - accuracy: 0.4271\n","Epoch 91/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1248 - accuracy: 0.4293\n","Epoch 92/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1195 - accuracy: 0.4252\n","Epoch 93/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1140 - accuracy: 0.4228\n","Epoch 94/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1084 - accuracy: 0.4222\n","Epoch 95/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.1025 - accuracy: 0.4178\n","Epoch 96/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.0965 - accuracy: 0.4187\n","Epoch 97/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.0904 - accuracy: 0.4187\n","Epoch 98/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.0841 - accuracy: 0.4174\n","Epoch 99/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.0775 - accuracy: 0.4129\n","Epoch 100/100\n","300/300 [==============================] - 1s 3ms/step - loss: 2.0708 - accuracy: 0.4150\n"]}]},{"cell_type":"code","metadata":{"id":"ThB85Acn7SFu","outputId":"c9c59461-2291-471d-fa75-40ee6650ca1c","executionInfo":{"status":"ok","timestamp":1653502451732,"user_tz":-330,"elapsed":1782,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["results = model.evaluate(X_test, y_test)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 2ms/step - loss: 2.0686 - accuracy: 0.4079\n"]}]},{"cell_type":"code","metadata":{"id":"Iq5a7na67UgU","outputId":"cbd9c062-9283-463a-9617-1e174b05594e","executionInfo":{"status":"ok","timestamp":1653502451734,"user_tz":-330,"elapsed":22,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Test accuracy: ', results[1])"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy:  0.40790000557899475\n"]}]},{"cell_type":"markdown","metadata":{"id":"c5M6EHv17YUV"},"source":["### 2. Nonlinearity (Activation function)\n","\n","Sigmoid functions suffer from gradient vanishing problem, making training slower\n","\n","There are many choices apart from sigmoid and tanh; try many of them!\n","\n","'relu' (rectified linear unit) is one of the most popular ones\n","\n","Ref: https://keras.io/activations/"]},{"cell_type":"code","metadata":{"id":"BuuRRvxL7WU1","executionInfo":{"status":"ok","timestamp":1653502451734,"user_tz":-330,"elapsed":16,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["def mlp_model():\n","    model = Sequential()\n","    \n","    model.add(Dense(50, input_shape = (784, )))\n","    model.add(Activation('relu'))    \n","    model.add(Dense(50))\n","    model.add(Activation('relu'))    \n","    model.add(Dense(50))\n","    model.add(Activation('relu'))    \n","    model.add(Dense(50))\n","    model.add(Activation('relu'))    \n","    model.add(Dense(10))\n","    model.add(Activation('softmax'))\n","    \n","    sgd = optimizers.SGD(lr = 0.001)\n","    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    \n","    return model"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"LHqen6477eRZ","outputId":"51851f3e-caa9-486a-e19f-2254755b7898","executionInfo":{"status":"ok","timestamp":1653502495937,"user_tz":-330,"elapsed":44218,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["model = mlp_model()\n","history = model.fit(X_train, y_train, epochs = 10, verbose = 1)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["1875/1875 [==============================] - 5s 2ms/step - loss: 0.9766 - accuracy: 0.7057\n","Epoch 2/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.5850 - accuracy: 0.7910\n","Epoch 3/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.5207 - accuracy: 0.8123\n","Epoch 4/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4841 - accuracy: 0.8250\n","Epoch 5/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4597 - accuracy: 0.8332\n","Epoch 6/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4442 - accuracy: 0.8379\n","Epoch 7/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4291 - accuracy: 0.8441\n","Epoch 8/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4173 - accuracy: 0.8492\n","Epoch 9/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.4077 - accuracy: 0.8529\n","Epoch 10/10\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.3995 - accuracy: 0.8553\n"]}]},{"cell_type":"code","metadata":{"id":"LLrEe_Kn7fha","outputId":"8f2cdebf-7605-477d-973d-af07ebc2372c","executionInfo":{"status":"ok","timestamp":1653502497834,"user_tz":-330,"elapsed":1905,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["results = model.evaluate(X_test, y_test)\n"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 2ms/step - loss: 0.4745 - accuracy: 0.8268\n"]}]},{"cell_type":"code","metadata":{"id":"BBUqrqSd7heP","outputId":"a45b9aa2-403f-4521-a63f-d17062360600","executionInfo":{"status":"ok","timestamp":1653502497835,"user_tz":-330,"elapsed":18,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Test accuracy: ', results[1])"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy:  0.8267999887466431\n"]}]},{"cell_type":"markdown","metadata":{"id":"lp_-o2ug70fF"},"source":["### 3. Batch Normalization\n","\n","Batch Normalization, one of the methods to prevent the \"internal covariance shift\" problem, has proven to be highly effective\n","\n","Normalize each mini-batch before nonlinearity\n","\n","Ref: https://keras.io/optimizers/"]},{"cell_type":"code","metadata":{"id":"buhn2kOY7yg8","executionInfo":{"status":"ok","timestamp":1653502497835,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["from tensorflow.keras.layers import BatchNormalization, Dropout\n"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8YrSd0LT78Yi"},"source":["Batch normalization layer is usually inserted after dense/convolution and before nonlinearity\n","\n"]},{"cell_type":"code","metadata":{"id":"10InY0e_77M7","executionInfo":{"status":"ok","timestamp":1653502497836,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["def mlp_model():\n","    model = Sequential()\n","    \n","    model.add(Dense(50, input_shape = (784, )))\n","    model.add(BatchNormalization())                    \n","    model.add(Activation('relu'))    \n","    model.add(Dense(50))\n","    model.add(BatchNormalization())                    \n","    model.add(Activation('relu'))    \n","    model.add(Dense(50))\n","    model.add(BatchNormalization())                    \n","    model.add(Activation('relu'))    \n","    model.add(Dense(50))\n","    model.add(BatchNormalization())                    \n","    model.add(Activation('relu'))    \n","    model.add(Dense(10))\n","    model.add(Activation('softmax'))\n","    \n","    sgd = optimizers.SGD(lr = 0.001)\n","    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    \n","    return model"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOCywkTg79_W","outputId":"8dafba2a-cdda-4861-dc5e-1b582ada4b98","executionInfo":{"status":"ok","timestamp":1653502626208,"user_tz":-330,"elapsed":128384,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["model = mlp_model()\n","history = model.fit(X_train, y_train, epochs = 20, verbose = 1)\n"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["1875/1875 [==============================] - 8s 4ms/step - loss: 1.3590 - accuracy: 0.5905\n","Epoch 2/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.8479 - accuracy: 0.7397\n","Epoch 3/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.7169 - accuracy: 0.7679\n","Epoch 4/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.6477 - accuracy: 0.7849\n","Epoch 5/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.6066 - accuracy: 0.7967\n","Epoch 6/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.5730 - accuracy: 0.8077\n","Epoch 7/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.5494 - accuracy: 0.8145\n","Epoch 8/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.5278 - accuracy: 0.8190\n","Epoch 9/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.5110 - accuracy: 0.8242\n","Epoch 10/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.5001 - accuracy: 0.8281\n","Epoch 11/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4879 - accuracy: 0.8325\n","Epoch 12/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4775 - accuracy: 0.8360\n","Epoch 13/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4683 - accuracy: 0.8369\n","Epoch 14/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4607 - accuracy: 0.8398\n","Epoch 15/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4526 - accuracy: 0.8425\n","Epoch 16/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4432 - accuracy: 0.8455\n","Epoch 17/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4395 - accuracy: 0.8474\n","Epoch 18/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4360 - accuracy: 0.8494\n","Epoch 19/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4283 - accuracy: 0.8509\n","Epoch 20/20\n","1875/1875 [==============================] - 6s 3ms/step - loss: 0.4241 - accuracy: 0.8514\n"]}]},{"cell_type":"code","metadata":{"id":"gGodrhsc8AW7","outputId":"2d5de751-3707-4b99-c6eb-4641ceec08c1","executionInfo":{"status":"ok","timestamp":1653502627350,"user_tz":-330,"elapsed":1150,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["results = model.evaluate(X_test, y_test)"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.3990 - accuracy: 0.8596\n"]}]},{"cell_type":"code","metadata":{"id":"zDnDxm8r8Bt0","outputId":"8e1e797a-63bf-4306-c3e7-7e1dceca36ce","executionInfo":{"status":"ok","timestamp":1653502627352,"user_tz":-330,"elapsed":17,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Test accuracy: ', results[1])\n"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy:  0.8596000075340271\n"]}]},{"cell_type":"markdown","metadata":{"id":"ElSuYRBH8yim"},"source":["### Dropout"]},{"cell_type":"code","metadata":{"id":"gKXR7REP8C8s","executionInfo":{"status":"ok","timestamp":1653502627353,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":["def mlp_model():\n","    model = Sequential()\n","    \n","    model.add(Dense(50, input_shape = (784, ), kernel_initializer='he_normal'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(50, kernel_initializer='he_normal'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))    \n","    model.add(Dropout(0.2))\n","    model.add(Dense(50, kernel_initializer='he_normal'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(50, kernel_initializer='he_normal'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(10, kernel_initializer='he_normal'))\n","    model.add(Activation('softmax'))\n","    \n","    adam = optimizers.Adam(lr = 0.001)\n","    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    \n","    return model"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"8FJsCqh680bq","outputId":"3c939554-546d-441c-b6fe-fef37dc11ab9","executionInfo":{"status":"ok","timestamp":1653502710617,"user_tz":-330,"elapsed":83275,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["model = mlp_model()\n","history = model.fit(X_train, y_train, epochs = 10, verbose = 1)"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["1875/1875 [==============================] - 9s 4ms/step - loss: 0.8613 - accuracy: 0.7046\n","Epoch 2/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.6037 - accuracy: 0.7973\n","Epoch 3/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.5446 - accuracy: 0.8153\n","Epoch 4/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.5206 - accuracy: 0.8236\n","Epoch 5/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.5036 - accuracy: 0.8282\n","Epoch 6/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.4810 - accuracy: 0.8340\n","Epoch 7/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.4627 - accuracy: 0.8399\n","Epoch 8/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.4552 - accuracy: 0.8447\n","Epoch 9/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.4486 - accuracy: 0.8470\n","Epoch 10/10\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.4420 - accuracy: 0.8482\n"]}]},{"cell_type":"code","metadata":{"id":"TY58JhC085IM","outputId":"d5499954-f571-44ed-f442-af4fb2b27ef6","executionInfo":{"status":"ok","timestamp":1653502711885,"user_tz":-330,"elapsed":1284,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["results = model.evaluate(X_test, y_test)"],"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.3796 - accuracy: 0.8620\n"]}]},{"cell_type":"code","metadata":{"id":"SU5NUjzs85KT","outputId":"9accee57-a722-4762-d5d6-fd3a196389f9","executionInfo":{"status":"ok","timestamp":1653502711886,"user_tz":-330,"elapsed":24,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Test accuracy: ', results[1])\n"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy:  0.8619999885559082\n"]}]},{"cell_type":"code","metadata":{"id":"tb66vQo-KsM_","executionInfo":{"status":"ok","timestamp":1653502711886,"user_tz":-330,"elapsed":17,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"source":[""],"execution_count":32,"outputs":[]}]}
{"cells":[{"cell_type":"markdown","metadata":{"id":"E8Cr_8mxAoXv"},"source":["# Neural network basics\n","----"]},{"cell_type":"markdown","metadata":{"id":"EW_K9epZzhSr"},"source":["### Package Version\n","- tensorflow==2.3.0\n","- scikit-learn==0.22.2.post1\n","- pandas==1.1.4"]},{"cell_type":"markdown","metadata":{"id":"6vb8VyrqAoXy"},"source":["## Given a Bank customer, can we build a classifier which can determine whether they will leave or not using Neural networks?\n","The case study is from an open source dataset from Kaggle.\n","\n","Link to the Kaggle project site:\n","https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling"]},{"cell_type":"markdown","metadata":{"id":"UvmWcU4Y2MCO"},"source":["### Read the dataset"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3vEBrZfs2jD","outputId":"050b5f79-ea29-4c89-cb95-8d027f4e4441","executionInfo":{"status":"ok","timestamp":1649328027714,"user_tz":-330,"elapsed":38819,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kybBDG1V2MCP","executionInfo":{"status":"ok","timestamp":1649328029177,"user_tz":-330,"elapsed":1476,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["import pandas as pd\n","\n","ds = pd.read_csv(\"/content/drive/MyDrive/AIML Program/Practice/Neural Network /week 1/Churn (1).csv\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":362},"id":"rPnhjSxC2MCS","outputId":"6f87335b-f9fd-47b3-d2c7-1b2cda31b197","executionInfo":{"status":"ok","timestamp":1649328029179,"user_tz":-330,"elapsed":38,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n","0          1    15634602  Hargrave          619    France  Female   42   \n","1          2    15647311      Hill          608     Spain  Female   41   \n","2          3    15619304      Onio          502    France  Female   42   \n","3          4    15701354      Boni          699    France  Female   39   \n","4          5    15737888  Mitchell          850     Spain  Female   43   \n","5          6    15574012       Chu          645     Spain    Male   44   \n","6          7    15592531  Bartlett          822    France    Male   50   \n","7          8    15656148    Obinna          376   Germany  Female   29   \n","8          9    15792365        He          501    France    Male   44   \n","9         10    15592389        H?          684    France    Male   27   \n","\n","   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n","0       2       0.00              1          1               1   \n","1       1   83807.86              1          0               1   \n","2       8  159660.80              3          1               0   \n","3       1       0.00              2          0               0   \n","4       2  125510.82              1          1               1   \n","5       8  113755.78              2          1               0   \n","6       7       0.00              2          1               1   \n","7       4  115046.74              4          1               0   \n","8       4  142051.07              2          0               1   \n","9       2  134603.88              1          1               1   \n","\n","   EstimatedSalary  Exited  \n","0        101348.88       1  \n","1        112542.58       0  \n","2        113931.57       1  \n","3         93826.63       0  \n","4         79084.10       0  \n","5        149756.71       1  \n","6         10062.80       0  \n","7        119346.88       1  \n","8         74940.50       0  \n","9         71725.73       0  "],"text/html":["\n","  <div id=\"df-dc36292c-26c9-41b8-a4f7-c4aa66c54200\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RowNumber</th>\n","      <th>CustomerId</th>\n","      <th>Surname</th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>15634602</td>\n","      <td>Hargrave</td>\n","      <td>619</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>15647311</td>\n","      <td>Hill</td>\n","      <td>608</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>15619304</td>\n","      <td>Onio</td>\n","      <td>502</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>15701354</td>\n","      <td>Boni</td>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>15737888</td>\n","      <td>Mitchell</td>\n","      <td>850</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>15574012</td>\n","      <td>Chu</td>\n","      <td>645</td>\n","      <td>Spain</td>\n","      <td>Male</td>\n","      <td>44</td>\n","      <td>8</td>\n","      <td>113755.78</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>149756.71</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>15592531</td>\n","      <td>Bartlett</td>\n","      <td>822</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>50</td>\n","      <td>7</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>10062.80</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>15656148</td>\n","      <td>Obinna</td>\n","      <td>376</td>\n","      <td>Germany</td>\n","      <td>Female</td>\n","      <td>29</td>\n","      <td>4</td>\n","      <td>115046.74</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>119346.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>15792365</td>\n","      <td>He</td>\n","      <td>501</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>44</td>\n","      <td>4</td>\n","      <td>142051.07</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>74940.50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>15592389</td>\n","      <td>H?</td>\n","      <td>684</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>27</td>\n","      <td>2</td>\n","      <td>134603.88</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>71725.73</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc36292c-26c9-41b8-a4f7-c4aa66c54200')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dc36292c-26c9-41b8-a4f7-c4aa66c54200 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dc36292c-26c9-41b8-a4f7-c4aa66c54200');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}],"source":["ds.head(10)"]},{"cell_type":"markdown","metadata":{"id":"E5FCBQRi2MCX"},"source":["### Drop the columns which are unique for all users like IDs"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjYdG1Me2MCY","outputId":"7c0ce197-25ea-4e4c-9bb7-858e36eea421","executionInfo":{"status":"ok","timestamp":1649328029180,"user_tz":-330,"elapsed":32,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["France     5014\n","Germany    2509\n","Spain      2477\n","Name: Geography, dtype: int64"]},"metadata":{},"execution_count":4}],"source":["ds['Geography'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"Vc0cjbTvAoYR"},"source":["### RowNumber, CustomerId, and Surname are unique hence we are dropping it"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Zi8q9XEv2MCf","executionInfo":{"status":"ok","timestamp":1649328029181,"user_tz":-330,"elapsed":24,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["ds = ds.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"coCQRBbm2MCj","outputId":"d9834818-0611-45f4-e316-07803f723379","executionInfo":{"status":"ok","timestamp":1649328029181,"user_tz":-330,"elapsed":23,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 11 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   CreditScore      10000 non-null  int64  \n"," 1   Geography        10000 non-null  object \n"," 2   Gender           10000 non-null  object \n"," 3   Age              10000 non-null  int64  \n"," 4   Tenure           10000 non-null  int64  \n"," 5   Balance          10000 non-null  float64\n"," 6   NumOfProducts    10000 non-null  int64  \n"," 7   HasCrCard        10000 non-null  int64  \n"," 8   IsActiveMember   10000 non-null  int64  \n"," 9   EstimatedSalary  10000 non-null  float64\n"," 10  Exited           10000 non-null  int64  \n","dtypes: float64(2), int64(7), object(2)\n","memory usage: 859.5+ KB\n"]}],"source":["ds.info()"]},{"cell_type":"markdown","metadata":{"id":"B8eWh6ox2MCp"},"source":["### Distinguish the feature and target set"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gY_wiurk2MCq","executionInfo":{"status":"ok","timestamp":1649328029182,"user_tz":-330,"elapsed":18,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["X = ds.iloc[:,0:10].values # Credit Score through Estimated Salary\n","y = ds.iloc[:,10].values # Exited"]},{"cell_type":"markdown","metadata":{"id":"oHlmxWHUAoYf"},"source":["### Encoding categorical (string based) data. Country: there are 3 options: France, Spain and Germany. This will convert those strings into scalar values for analysis."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jOroI5WQ2MCu","outputId":"c77c8582-7d15-411c-9a58-6d422aa90dd3","executionInfo":{"status":"ok","timestamp":1649328029880,"user_tz":-330,"elapsed":715,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['France' 'Spain' 'France' 'France' 'Spain' 'Spain' 'France' 'Germany'] ... will now become: \n","[0 2 0 0 2 2 0 1]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","print(X[:8,1], '... will now become: ')\n","\n","label_X_country_encoder = LabelEncoder()\n","X[:,1] = label_X_country_encoder.fit_transform(X[:,1])\n","print(X[:8,1])"]},{"cell_type":"markdown","metadata":{"id":"VKStPf-YAoYj"},"source":["### We will do the same thing for gender. this will be binary in this dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e-twfXkV2MCz","outputId":"3b5f5eb9-6d99-468e-e710-b96a5b3b2338","executionInfo":{"status":"ok","timestamp":1649328029881,"user_tz":-330,"elapsed":27,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['Female' 'Female' 'Female' 'Female' 'Female' 'Male'] ... will now become: \n","[0 0 0 0 0 1]\n"]}],"source":["print(X[:6,2], '... will now become: ')\n","\n","label_X_gender_encoder = LabelEncoder()\n","X[:,2] = label_X_gender_encoder.fit_transform(X[:,2])\n","print(X[:6,2])"]},{"cell_type":"markdown","metadata":{"id":"gkPMURW4AoYn"},"source":["### The Problem here is that we are treating the countries as one variable with ordinal values (0 < 1 < 2). Therefore, one way to get rid of that problem is to split the countries into respective dimensions. Gender does not need this as it is binary\n","\n","### Converting the string features into their own dimensions. Gender doesn't matter here because its binary"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"h5xaQNH_2MC3","executionInfo":{"status":"ok","timestamp":1649328029882,"user_tz":-330,"elapsed":22,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","\n","transform = ColumnTransformer([(\"countries\", OneHotEncoder(), [1])], remainder=\"passthrough\") # 1 is the country column\n","X = transform.fit_transform(X)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wmwM4OOr2MC7","outputId":"3897751a-ddc7-46fb-860c-b48b5c4f97c9","executionInfo":{"status":"ok","timestamp":1649328029883,"user_tz":-330,"elapsed":22,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 12)"]},"metadata":{},"execution_count":11}],"source":["X.shape"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gG4wSXrB2MDC","outputId":"71630d99-6cf9-4321-8c08-de8c5f260cf1","executionInfo":{"status":"ok","timestamp":1649328029883,"user_tz":-330,"elapsed":18,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.0, 0.0, 0.0, ..., 1, 1, 101348.88],\n","       [0.0, 0.0, 1.0, ..., 0, 1, 112542.58],\n","       [1.0, 0.0, 0.0, ..., 1, 0, 113931.57],\n","       ...,\n","       [1.0, 0.0, 0.0, ..., 0, 1, 42085.58],\n","       [0.0, 1.0, 0.0, ..., 1, 0, 92888.52],\n","       [1.0, 0.0, 0.0, ..., 1, 0, 38190.78]], dtype=object)"]},"metadata":{},"execution_count":12}],"source":["X"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"26EuNLE62MDH","executionInfo":{"status":"ok","timestamp":1649328029884,"user_tz":-330,"elapsed":14,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["# A 0 on two countries means that the country has to be the one variable which wasn't included \n","# This will save us from the problem of using too many dimensions\n","X = X[:,1:] # Got rid of Spain as a dimension."]},{"cell_type":"markdown","metadata":{"id":"5G-irNPm2MDL"},"source":["### Divide the data set into Train and test sets"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"G-JdmcgH2MDM","executionInfo":{"status":"ok","timestamp":1649328029884,"user_tz":-330,"elapsed":13,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Splitting the dataset into the Training and Testing set\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)"]},{"cell_type":"markdown","metadata":{"id":"v59orwv_2MDQ"},"source":["### Normalize the train and test data"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"8TqBQADf2MDR","executionInfo":{"status":"ok","timestamp":1649328029884,"user_tz":-330,"elapsed":12,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","\n","sc=StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"h14ysgXo2MDU"},"source":["### Initialize & build the model"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"lMyjKipO2MDV","executionInfo":{"status":"ok","timestamp":1649328033129,"user_tz":-330,"elapsed":3257,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","\n","# Initializing the ANN\n","classifier = Sequential()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"O3ecignQ2MDX","executionInfo":{"status":"ok","timestamp":1649328033130,"user_tz":-330,"elapsed":22,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["\n","from tensorflow.keras.layers import Dense\n","\n","# The amount of nodes (dimensions) in hidden layer should be the average of input and output layers, in this case 6.\n","# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n","classifier.add(Dense(activation = 'relu', input_dim = 11, units=6, kernel_initializer='uniform'))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ov1vaKOW2MDa","executionInfo":{"status":"ok","timestamp":1649328033131,"user_tz":-330,"elapsed":22,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["#Add 1st hidden layer\n","classifier.add(Dense(6, activation='sigmoid', kernel_initializer='uniform'))"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Brkoooyr2MDd","executionInfo":{"status":"ok","timestamp":1649328033132,"user_tz":-330,"elapsed":22,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["# Adding the output layer\n","# Notice that we do not need to specify input dim. \n","# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n","# We use the sigmoid because we want probability outcomes\n","classifier.add(Dense(1, activation = 'sigmoid', kernel_initializer='uniform')) "]},{"cell_type":"code","execution_count":20,"metadata":{"id":"3IMvDnr92MDh","executionInfo":{"status":"ok","timestamp":1649328033132,"user_tz":-330,"elapsed":21,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["# Create optimizer with default learning rate\n","# sgd_optimizer = tf.keras.optimizers.SGD()\n","# Compile the model\n","classifier.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E4UqHZj82MDj","outputId":"5aaded89-f134-488b-c389-1db7be15879f","executionInfo":{"status":"ok","timestamp":1649328033133,"user_tz":-330,"elapsed":21,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 6)                 72        \n","                                                                 \n"," dense_1 (Dense)             (None, 6)                 42        \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 7         \n","                                                                 \n","=================================================================\n","Total params: 121\n","Trainable params: 121\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["classifier.summary()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NErktj342MDo","outputId":"c1701214-7e18-4bf0-b76c-cf76935674d9","executionInfo":{"status":"ok","timestamp":1649328116071,"user_tz":-330,"elapsed":82951,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.2088 - accuracy: 0.7857 - val_loss: 0.1829 - val_accuracy: 0.7975\n","Epoch 2/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.7960 - val_loss: 0.1683 - val_accuracy: 0.7975\n","Epoch 3/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.7960 - val_loss: 0.1641 - val_accuracy: 0.7975\n","Epoch 4/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.7960 - val_loss: 0.1627 - val_accuracy: 0.7975\n","Epoch 5/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.7960 - val_loss: 0.1621 - val_accuracy: 0.7975\n","Epoch 6/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.7960 - val_loss: 0.1618 - val_accuracy: 0.7975\n","Epoch 7/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.7960 - val_loss: 0.1616 - val_accuracy: 0.7975\n","Epoch 8/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.7960 - val_loss: 0.1616 - val_accuracy: 0.7975\n","Epoch 9/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 10/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 11/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 12/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 13/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 14/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 15/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 16/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 17/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 18/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 19/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 20/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 21/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 22/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 23/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 24/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 25/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 26/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 27/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 28/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 29/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 30/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 31/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 32/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 33/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 34/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 35/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 36/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 37/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 38/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 39/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 40/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 41/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 42/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 43/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 44/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 45/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 46/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 47/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 48/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 49/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 50/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 51/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 52/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 53/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 54/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 55/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 56/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 57/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 58/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 59/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 60/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 61/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 62/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 63/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 64/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 65/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 66/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 67/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 68/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 69/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 70/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 71/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 72/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 73/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 74/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 75/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 76/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 77/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 78/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 79/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 80/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 81/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 82/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 83/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 84/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 85/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 86/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 87/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 88/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 89/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 90/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 91/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 92/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 93/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 94/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 95/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 96/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 97/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 98/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 99/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 100/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f105a324a50>"]},"metadata":{},"execution_count":22}],"source":["classifier.fit(X_train, y_train,           \n","          validation_data=(X_test,y_test),\n","          epochs=100,\n","          batch_size=32)"]},{"cell_type":"markdown","metadata":{"id":"aXUi_lqe2MDs"},"source":["### Predict the results using 0.5 as a threshold"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GxXO6--h2MDt","outputId":"43b47aa4-ddb6-497d-b0b0-3ab873f59668","executionInfo":{"status":"ok","timestamp":1649328116072,"user_tz":-330,"elapsed":36,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.20423672]\n"," [0.20417789]\n"," [0.2040751 ]\n"," ...\n"," [0.2036168 ]\n"," [0.20400187]\n"," [0.20384601]]\n"]}],"source":["y_pred = classifier.predict(X_test)\n","print(y_pred)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EIPDxM892MDw","outputId":"d24e187e-9349-4d0a-a8e0-a346c73a24e0","executionInfo":{"status":"ok","timestamp":1649328116072,"user_tz":-330,"elapsed":28,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[[False]\n"," [False]\n"," [False]\n"," ...\n"," [False]\n"," [False]\n"," [False]]\n"]}],"source":["# To use the confusion Matrix, we need to convert the probabilities that a customer will leave the bank into the form true or false. \n","# So we will use the cutoff value 0.5 to indicate whether they are likely to exit or not.\n","y_pred = (y_pred > 0.5)\n","print(y_pred)"]},{"cell_type":"markdown","metadata":{"id":"VkX2OXIb2MD1"},"source":["### Print the Accuracy score and confusion matrix"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Bx-Xgej2MD1","outputId":"5fe38bfa-0897-4a41-8589-f831b8939fed","executionInfo":{"status":"ok","timestamp":1649328116073,"user_tz":-330,"elapsed":25,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[[1595    0]\n"," [ 405    0]]\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","\n","cm1 = confusion_matrix(y_test, y_pred)\n","print(cm1)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nwXHTVc2MD4","outputId":"c8f60116-5472-4988-c7fb-a857266e039a","executionInfo":{"status":"ok","timestamp":1649328116074,"user_tz":-330,"elapsed":22,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["79.75 % of testing data was classified correctly\n"]}],"source":["accuracy_model1 = ((cm1[0][0]+cm1[1][1])*100)/(cm1[0][0]+cm1[1][1]+cm1[0][1]+cm1[1][0])\n","print (accuracy_model1, '% of testing data was classified correctly')"]},{"cell_type":"markdown","metadata":{"id":"ITHuG0BY2MD7"},"source":["### Optimize the model"]},{"cell_type":"markdown","metadata":{"id":"ilZJGtVw2MD8"},"source":["Some important parameters to look out for while optimizing neural networks are:\n","\n","-Type of architecture\n","\n","-Number of Layers\n","\n","-Number of Neurons in a layer\n","\n","-Regularization parameters\n","\n","-Learning Rate\n","\n","-Type of optimization / backpropagation technique to use\n","\n","-Dropout rate\n","\n","-Weight sharing"]},{"cell_type":"markdown","metadata":{"id":"NfcLaivq2MD9"},"source":["#### Number of Layers:\n","We will keep it similar to the above model so that we can compare the accuracy.\n","1 hidden layer.\n","\n","#### Activation:\n","input layer: relu becasue we are in an input layer. uses the ReLu activation function for  ϕ\n","output layer: sigmoid becasue we are in an output layer. uses the Sigmoid activation function for  ϕ . This is used instead of the ReLu function becasue it generates probabilities for the outcome. We want the probability that each customer leaves the bank.\n","\n","#### Type of optimization / backpropagation technique to use: \n","We will use Adam. Adam is a very efficeint variation of Stochastic Gradient Descent. For Adam and its variant, learning rate or the decay rate does not really matter too much.\n","\n","#### Learning Rate:\n","default learning rate 0.001.\n","\n","#### Number of Neurons in a layer:\n","We will keep it 6 as per our initial calculation above.\n","\n","#### Weight sharing / kernel_initializer: \n","uniform the distribution with which we randomly initialize weights for the nodes in this layer.\n","\n","#### Loss:\n","loss: binary_crossentropy This is the loss function used within adam. This should be the logarthmic loss. If our dependent (output variable) is Binary, it is binary_crossentropy. If Categorical, then it is called categorical_crossentropy\n","\n","### Rebuilding the model using these optimised parameters"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"TYBOVfnW2MEB","executionInfo":{"status":"ok","timestamp":1649328116074,"user_tz":-330,"elapsed":17,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["# Initializing the ANN\n","classifier = Sequential()\n","# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n","classifier.add(Dense(activation = 'relu', input_dim = 11, units=6, kernel_initializer='uniform'))"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"1CAa_tm82MEF","executionInfo":{"status":"ok","timestamp":1649328116075,"user_tz":-330,"elapsed":17,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["# Adding the hidden layer\n","# Notice that we do not need to specify input dim. \n","classifier.add(Dense(activation = 'relu', units=6, kernel_initializer='uniform')) "]},{"cell_type":"code","execution_count":29,"metadata":{"id":"AzZPPFIZ2MEI","executionInfo":{"status":"ok","timestamp":1649328116075,"user_tz":-330,"elapsed":16,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["# Adding the output layer\n","# Notice that we do not need to specify input dim. \n","# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n","# We use the sigmoid because we want probability outcomes\n","classifier.add(Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform')) "]},{"cell_type":"code","execution_count":30,"metadata":{"id":"7PNJ1TPS2MEK","executionInfo":{"status":"ok","timestamp":1649328116076,"user_tz":-330,"elapsed":16,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[],"source":["classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NbUkhk902MEM","outputId":"a88243a7-1e1a-4016-cba5-1a177d495c4b","executionInfo":{"status":"ok","timestamp":1649328166483,"user_tz":-330,"elapsed":50423,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.6302 - accuracy: 0.7935 - val_loss: 0.5216 - val_accuracy: 0.7975\n","Epoch 2/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.7981 - val_loss: 0.4194 - val_accuracy: 0.8130\n","Epoch 3/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8307 - val_loss: 0.3789 - val_accuracy: 0.8510\n","Epoch 4/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3745 - accuracy: 0.8444 - val_loss: 0.3603 - val_accuracy: 0.8560\n","Epoch 5/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8486 - val_loss: 0.3520 - val_accuracy: 0.8580\n","Epoch 6/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3560 - accuracy: 0.8511 - val_loss: 0.3481 - val_accuracy: 0.8590\n","Epoch 7/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8531 - val_loss: 0.3464 - val_accuracy: 0.8575\n","Epoch 8/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8541 - val_loss: 0.3458 - val_accuracy: 0.8550\n","Epoch 9/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8564 - val_loss: 0.3460 - val_accuracy: 0.8560\n","Epoch 10/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3471 - accuracy: 0.8562 - val_loss: 0.3427 - val_accuracy: 0.8560\n","Epoch 11/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.8585 - val_loss: 0.3441 - val_accuracy: 0.8545\n","Epoch 12/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8576 - val_loss: 0.3411 - val_accuracy: 0.8600\n","Epoch 13/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8608 - val_loss: 0.3416 - val_accuracy: 0.8565\n","Epoch 14/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8616 - val_loss: 0.3392 - val_accuracy: 0.8575\n","Epoch 15/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8616 - val_loss: 0.3389 - val_accuracy: 0.8575\n","Epoch 16/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3421 - accuracy: 0.8606 - val_loss: 0.3391 - val_accuracy: 0.8555\n","Epoch 17/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8625 - val_loss: 0.3401 - val_accuracy: 0.8550\n","Epoch 18/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8609 - val_loss: 0.3370 - val_accuracy: 0.8600\n","Epoch 19/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3405 - accuracy: 0.8597 - val_loss: 0.3385 - val_accuracy: 0.8555\n","Epoch 20/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8619 - val_loss: 0.3395 - val_accuracy: 0.8530\n","Epoch 21/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8622 - val_loss: 0.3392 - val_accuracy: 0.8565\n","Epoch 22/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8615 - val_loss: 0.3355 - val_accuracy: 0.8640\n","Epoch 23/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8630 - val_loss: 0.3358 - val_accuracy: 0.8560\n","Epoch 24/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8624 - val_loss: 0.3370 - val_accuracy: 0.8585\n","Epoch 25/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8619 - val_loss: 0.3352 - val_accuracy: 0.8620\n","Epoch 26/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3380 - accuracy: 0.8624 - val_loss: 0.3350 - val_accuracy: 0.8585\n","Epoch 27/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8619 - val_loss: 0.3351 - val_accuracy: 0.8585\n","Epoch 28/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8626 - val_loss: 0.3352 - val_accuracy: 0.8590\n","Epoch 29/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8629 - val_loss: 0.3368 - val_accuracy: 0.8575\n","Epoch 30/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.8624 - val_loss: 0.3351 - val_accuracy: 0.8565\n","Epoch 31/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8646 - val_loss: 0.3344 - val_accuracy: 0.8620\n","Epoch 32/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3364 - accuracy: 0.8625 - val_loss: 0.3344 - val_accuracy: 0.8620\n","Epoch 33/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8648 - val_loss: 0.3362 - val_accuracy: 0.8595\n","Epoch 34/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8648 - val_loss: 0.3330 - val_accuracy: 0.8620\n","Epoch 35/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8651 - val_loss: 0.3349 - val_accuracy: 0.8615\n","Epoch 36/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8641 - val_loss: 0.3332 - val_accuracy: 0.8610\n","Epoch 37/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8645 - val_loss: 0.3334 - val_accuracy: 0.8590\n","Epoch 38/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8636 - val_loss: 0.3339 - val_accuracy: 0.8610\n","Epoch 39/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3348 - accuracy: 0.8656 - val_loss: 0.3331 - val_accuracy: 0.8605\n","Epoch 40/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8651 - val_loss: 0.3332 - val_accuracy: 0.8620\n","Epoch 41/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8646 - val_loss: 0.3357 - val_accuracy: 0.8565\n","Epoch 42/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8639 - val_loss: 0.3365 - val_accuracy: 0.8590\n","Epoch 43/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8654 - val_loss: 0.3329 - val_accuracy: 0.8610\n","Epoch 44/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8634 - val_loss: 0.3323 - val_accuracy: 0.8630\n","Epoch 45/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8635 - val_loss: 0.3335 - val_accuracy: 0.8605\n","Epoch 46/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8652 - val_loss: 0.3341 - val_accuracy: 0.8595\n","Epoch 47/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8650 - val_loss: 0.3327 - val_accuracy: 0.8610\n","Epoch 48/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8637 - val_loss: 0.3343 - val_accuracy: 0.8590\n","Epoch 49/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8644 - val_loss: 0.3342 - val_accuracy: 0.8590\n","Epoch 50/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8636 - val_loss: 0.3336 - val_accuracy: 0.8615\n","Epoch 51/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8648 - val_loss: 0.3348 - val_accuracy: 0.8620\n","Epoch 52/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8639 - val_loss: 0.3324 - val_accuracy: 0.8605\n","Epoch 53/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8651 - val_loss: 0.3339 - val_accuracy: 0.8605\n","Epoch 54/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8644 - val_loss: 0.3329 - val_accuracy: 0.8615\n","Epoch 55/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8652 - val_loss: 0.3322 - val_accuracy: 0.8630\n","Epoch 56/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8639 - val_loss: 0.3339 - val_accuracy: 0.8595\n","Epoch 57/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8664 - val_loss: 0.3340 - val_accuracy: 0.8635\n","Epoch 58/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8654 - val_loss: 0.3333 - val_accuracy: 0.8600\n","Epoch 59/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8631 - val_loss: 0.3329 - val_accuracy: 0.8600\n","Epoch 60/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8644 - val_loss: 0.3332 - val_accuracy: 0.8595\n","Epoch 61/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8652 - val_loss: 0.3343 - val_accuracy: 0.8610\n","Epoch 62/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3324 - accuracy: 0.8646 - val_loss: 0.3342 - val_accuracy: 0.8640\n","Epoch 63/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8627 - val_loss: 0.3361 - val_accuracy: 0.8610\n","Epoch 64/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8654 - val_loss: 0.3330 - val_accuracy: 0.8600\n","Epoch 65/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8645 - val_loss: 0.3332 - val_accuracy: 0.8645\n","Epoch 66/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8646 - val_loss: 0.3369 - val_accuracy: 0.8580\n","Epoch 67/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8635 - val_loss: 0.3353 - val_accuracy: 0.8595\n","Epoch 68/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8651 - val_loss: 0.3354 - val_accuracy: 0.8570\n","Epoch 69/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8626 - val_loss: 0.3329 - val_accuracy: 0.8605\n","Epoch 70/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8664 - val_loss: 0.3346 - val_accuracy: 0.8575\n","Epoch 71/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8637 - val_loss: 0.3328 - val_accuracy: 0.8600\n","Epoch 72/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3324 - accuracy: 0.8631 - val_loss: 0.3338 - val_accuracy: 0.8600\n","Epoch 73/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8649 - val_loss: 0.3338 - val_accuracy: 0.8615\n","Epoch 74/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8640 - val_loss: 0.3321 - val_accuracy: 0.8620\n","Epoch 75/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8621 - val_loss: 0.3325 - val_accuracy: 0.8595\n","Epoch 76/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8640 - val_loss: 0.3330 - val_accuracy: 0.8590\n","Epoch 77/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8646 - val_loss: 0.3314 - val_accuracy: 0.8650\n","Epoch 78/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8636 - val_loss: 0.3342 - val_accuracy: 0.8575\n","Epoch 79/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8656 - val_loss: 0.3364 - val_accuracy: 0.8580\n","Epoch 80/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8640 - val_loss: 0.3328 - val_accuracy: 0.8610\n","Epoch 81/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8644 - val_loss: 0.3321 - val_accuracy: 0.8620\n","Epoch 82/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3323 - accuracy: 0.8643 - val_loss: 0.3359 - val_accuracy: 0.8555\n","Epoch 83/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8643 - val_loss: 0.3324 - val_accuracy: 0.8625\n","Epoch 84/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8646 - val_loss: 0.3322 - val_accuracy: 0.8615\n","Epoch 85/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8650 - val_loss: 0.3321 - val_accuracy: 0.8615\n","Epoch 86/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3323 - accuracy: 0.8646 - val_loss: 0.3333 - val_accuracy: 0.8620\n","Epoch 87/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8639 - val_loss: 0.3336 - val_accuracy: 0.8575\n","Epoch 88/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8643 - val_loss: 0.3341 - val_accuracy: 0.8580\n","Epoch 89/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3323 - accuracy: 0.8646 - val_loss: 0.3324 - val_accuracy: 0.8610\n","Epoch 90/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8649 - val_loss: 0.3326 - val_accuracy: 0.8620\n","Epoch 91/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8666 - val_loss: 0.3319 - val_accuracy: 0.8615\n","Epoch 92/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8633 - val_loss: 0.3328 - val_accuracy: 0.8625\n","Epoch 93/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8661 - val_loss: 0.3329 - val_accuracy: 0.8600\n","Epoch 94/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8644 - val_loss: 0.3321 - val_accuracy: 0.8605\n","Epoch 95/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8635 - val_loss: 0.3322 - val_accuracy: 0.8615\n","Epoch 96/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8643 - val_loss: 0.3321 - val_accuracy: 0.8615\n","Epoch 97/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8655 - val_loss: 0.3326 - val_accuracy: 0.8595\n","Epoch 98/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8634 - val_loss: 0.3330 - val_accuracy: 0.8580\n","Epoch 99/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8631 - val_loss: 0.3325 - val_accuracy: 0.8615\n","Epoch 100/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8658 - val_loss: 0.3374 - val_accuracy: 0.8565\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f105a2a18d0>"]},"metadata":{},"execution_count":31}],"source":["classifier.fit(X_train, y_train,           \n","          validation_data=(X_test,y_test),\n","          epochs=100,\n","          batch_size=32)"]},{"cell_type":"markdown","metadata":{"id":"qbkNCKVX2MEP"},"source":["### Predict the results using 0.5 as a threshold"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwMd3oJO2MEQ","outputId":"b0d7ff1b-ef16-4340-eb74-7008d8ec2924","executionInfo":{"status":"ok","timestamp":1649328166484,"user_tz":-330,"elapsed":56,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.27834982]\n"," [0.30297983]\n"," [0.11249137]\n"," ...\n"," [0.24985364]\n"," [0.14745301]\n"," [0.22850671]]\n"]}],"source":["y_pred = classifier.predict(X_test)\n","print(y_pred)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ppMSEGmq2MET","outputId":"3b04cd17-99cf-49f3-cd35-eaf32480ebd2","executionInfo":{"status":"ok","timestamp":1649328166485,"user_tz":-330,"elapsed":43,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[[False]\n"," [False]\n"," [False]\n"," ...\n"," [False]\n"," [False]\n"," [False]]\n"]}],"source":["# To use the confusion Matrix, we need to convert the probabilities that a customer will leave the bank into the form true or false. \n","# So we will use the cutoff value 0.5 to indicate whether they are likely to exit or not.\n","y_pred = (y_pred > 0.5)\n","print(y_pred)"]},{"cell_type":"markdown","metadata":{"id":"c1jh390C2MEW"},"source":["### Print the Accuracy score and confusion matrix"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3w6XYuiN2MEX","outputId":"13fbe79a-c488-4ccf-b6fe-8673ca8eba53","executionInfo":{"status":"ok","timestamp":1649328166485,"user_tz":-330,"elapsed":40,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[[1499   96]\n"," [ 191  214]]\n"]}],"source":["cm2 = confusion_matrix(y_test, y_pred)\n","print(cm2)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOklmKrD2MEf","outputId":"9a3f802a-b1ad-4b62-e66b-8e1a7f4eb802","executionInfo":{"status":"ok","timestamp":1649328166486,"user_tz":-330,"elapsed":36,"user":{"displayName":"Ashish Tiwari","userId":"08890013030836632194"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["85.65 % of testing data was classified correctly\n"]}],"source":["accuracy_model2 = ((cm2[0][0]+cm2[1][1])*100)/(cm2[0][0]+cm2[1][1]+cm2[0][1]+cm2[1][0])\n","print (accuracy_model2, '% of testing data was classified correctly')"]},{"cell_type":"markdown","metadata":{"id":"LiVey_K1zcbd"},"source":["<img src=\"http://drive.google.com/uc?export=view&id=1tpOCamr9aWz817atPnyXus8w5gJ3mIts\" width=500px>\n","\n","Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"week1_case_study_intro_to_nn_aiml_online (1).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":0}